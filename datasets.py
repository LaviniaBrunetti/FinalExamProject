import pandas as pd
from abc import ABC, abstractmethod




class Dataset:
    ''' An object that encloses a DataFrame. Is created by a DatasetReader. 
        Contains a self.df attribute that is a pandas dataframe object, generated by the reader by parsing the file. The attribute  self.result is defaulted to a string "Unavailable".
        Whenever an operation object is executed, the resulting Dataset object will store the result
        of the operation in the self.result attribute '''
    
    def __init__(self, df: pd.DataFrame, result= "Unavailable"):
        self.df= df
        self.result= result
        
    def show(self):
        '''Instance method, returns the pandas dataframe stored in self.df, showing all nine columns'''
        
        pd.set_option("display.max_columns", 9)
        pd.set_option("display.max_columns", None)
        print(self.df)
        return

     
    def show_result(self):
        '''Instance method, prints the self.result attribute'''
        
        return self.result
            
    
        
        
        
      
        
class GffDataset(Dataset):
    ''' subclass of DataSet, specific for the GFF format.  Implements a static method that creates a dictionary for the attributes of a GFF DataFrame  '''
    

    def __init__(self, df, result= "unavailable" ):
        super().__init__(df, result)
        
    @classmethod   
    def attributes_dict(cls, df) ->dict :
        '''' Takes a DataFrame as argument.
            returns a nested dictionary with all the attributes of an entry, for all entries of the dataset '''
        
        attributes_dict={}
        atts= df.loc[:, "Attributes"]
        
        for index in atts.index:
            val= {entry.split("=")[0]: entry.split("=")[1] for entry in atts[index].split(";")}
            attributes_dict[index]= val
            
        return attributes_dict






class Operation(ABC):
    ''' An abstract class that defines the general features of each operation. It contains a private register,
        i.e. a list of all active operation. Defines different methods to access/ modify the register, 
        .run defines the procedure to run the operation over the dataset object. .execute is an abstract method
        ment to specify the behaviour of each specific operation subclass '''
    
    #class attribute of active operations 
    __register=[ "get_columns", "get_ID", "get_type", "count_entries", "get_chromosomes", "count_fragmented", "get_ens_hav", "count_ens_hav", "get_gene_names" ]
    
  
    @staticmethod
    def _get_register():
        ''' Allows access to the register of active operation to the subclasses.
            Returns the register'''
        
        return Operation.__register
    
    @staticmethod
    def _set_register(reg:list):
        Operation.__register= reg
        return "Done"
    
    @staticmethod
    def _append_register(item:str):
        Operation.__register.append(item)
        return "Done"
    
        

    def manager(func):
        ''' Used to check if operations are active before executing them. It access the register, checks if the .name is present in the register and if so allows operation. otherwise returns a string'''
        def wrapper(self, data, **kwargs ):
            if self.name in Operation._get_register():
                res= func(self, data, **kwargs)
            else:
                res= "Operation is not active"
            return res
        return wrapper 
    
    
    @manager 
    def run(self, data, **kwargs):
        ''' Takes as arguments the caller object and a variable number of keyword arguments that will be passed to the nested _execute method. 
            Checks if the caller of the function is an instance of GFFDataSet. If it isn't it wil raise a ValueError and will not perform the operation.
            Performs the Operation and returns a GffDataset object. Handled by the manager'''
        
        #this is as to make the operation executable only by means of a dataset object OR subclass.
        if not isinstance (data, GffDataset):
            raise ValueError ("Operation can only be performed by an instance of Dataset class")
        
        #run the operation
        res= self._execute(data.df, **kwargs)
        
        #for all  operations, the result is stored in the new Dataset self.result attribute
        return GffDataset(None, res)
            
        
            
    
    @abstractmethod
    def _execute(self, df, **kwargs) -> Dataset:
        '''Abstract method. Meant to contain specific instruction for subclass behaviour'''
        pass

        
        
class get_columns(Operation):
    ''' Returns all the columns names and dtypes in the dataset'''
    
    def __init__(self):
        self.name= "get_columns"
    
      
    def _execute(self, df):
        ''' takes a dataframe as argument
        returns a string that contains information on the name and the type of data contained in each column of the dataset'''
        
        #create a list storing the names of the columns 
        cols=[i for i in df.columns]
        
        #create a list storing the dtypes for each column. In case the data type is object, the method will return "string" as object is a generic datatype that panda uses to address string-like entries.
        vals= [str(i) if i != "object" else "string" for i in df.dtypes ]
        
        #initialize result
        res= [f"This Dataset contains {len(cols)} columns"]
        
        #for each columns, add a line with the information
        for i in range(len(vals)):
            res.append(f" The column {cols[i]} contains objects of type {vals[i]}")
            
        #return a new dataset storing the result as attribute 
        return  res 



class get_ID(Operation):
    ''' returns a list or a series containing all the unique IDs present in the dataset'''
    
    def __init__(self):
        self.name= "get_ID"
    

    def _execute(self, df,  to_list: bool = True):
        
        ''' takes as arguments a dataframe and a to_list parameter which is by default set to False.
        if to_list==True returns a list of unique IDs, if false, returns a series with the unique IDs'''
        
         #create empty list
        res= ["Here you can find the unique IDs that are present in the Dataset"]
        ids= df["SeqID"]
            
        #if not present, add the ID to the list
        for i in ids:
            if i in res:
                continue
            res.append(i)
       
       #return the output according to to_list
        if to_list:
            return res
        elif not to_list:
             return pd.Series(res[1: ], name="Unique_IDs")
        else:
            raise ValueError("Invalid value for to_list")
        

class get_type(Operation):
    '''returns a list or a series containing the unique types containes in the dataset'''
    
    def __init__(self):
        self.name= "get_type"
     
    def _execute(self, df, to_list: bool = True):
        ''' takes as arguments a dataframe and a to_list parameter which is by default set to False. if to_list==True returns a list of unique types, if false, returns a series with the unique types'''
        #create empty list of type
        res= ["Here you can find the unique Types present in the Dataset"]
        types= df["Type"]
       
        #if not present, add type to the list 
        for i in types:
            if i in res:
                continue 
            res.append(i)
       
        #return result according to to_list
        if to_list:
             return res
        elif not to_list:
             return pd.Series(res[1:], name="Unique_Types")
        else:
             raise ValueError("Invalid value for to_list")
        
            
class count_entries(Operation):
    
    '''returns a list or a series with the number of entries for each type'''
    
    def __init__(self):
        self.name= "count_entries"
    
    
    
    def _execute(self, df, to_list=True):
        
        '''  Takes a dataframe as argument.
            Returns a Series or a list containing the number of features for each type.'''
        groups= df.groupby("Type").count()
        groups.sort_index()
        IDS=groups["SeqID"]
        res= ["Here you can find the number of entries for each type of feature" ]
        if to_list:
            for name, value in IDS.items():
               res.append(f"{name}: {value}")
            return res
        else:
            return IDS
            
        
    
    
    
class get_chromosomes(Operation):
    ''' returns a subset of the dataframe containing only the entries of whole chromosomes'''
    def __init__(self):
        self.name= "get_chromosomes"
    
   
    def _execute(self, df):
        '''  takes a dataframe as argument,
            returns a subset of the dataset that only contains feature with Source== GRCh38'''
        
        chrs= df[df["Source"]=="GRCh38"]
        return chrs
            
    

    
class count_fragmented(Operation):
    ''' returns a list or a dictionary containing information on fragmented sequences'''
    
    def __init__(self):
        self.name= "count_fragmented"
    
   
    def _execute (self, df, to_list=True):
        '''Takes a dataframe as argument.
            Selects only the entries of whole chromosomes, counts the number of fragmented sequences, the number of whole chromosome sequences and allows for "other" type of sequences. prints this information
            Returns a dictionary that contains the number of unassembled sequences, whole chromosome sequences and others, as well as the SeqID for the entries. ''' 
        
        #take only entire chromosomes 
        chrs= df[df["Source"]=="GRCh38"]
        
        fragmented= 0
        fragmented_ID=[]
        whole= 0
        whole_ID=[]
        other= 0
        other_ID=[]
        
        #count entries 
        for i in chrs.index:
            if "ID=supercontig" in chrs.loc[i, "Attributes"]:
                fragmented +=1
                fragmented_ID.append(chrs.loc[i, "SeqID"])
            elif "ID=chromosome" in chrs.loc[i, "Attributes"]:
                whole += 1
                whole_ID.append(chrs.loc[i, "SeqID"])
            else:
                other += 1
                other_ID.append(chrs.loc[i, "SeqID"])
        tot= whole + fragmented + other 
        fraction= fragmented/ tot
        if to_list:
            res= [f"UNASSEMBLED SEQUENCES: {fragmented}",  f"WHOLE CHROMOSOMES: {whole}", f"OTHER: {other}", f"FRACTION OF UNASSEMBLED SEQUENCES= {fraction}", f"UNASSEMBLED SEQUENCES IDs: {fragmented_ID}", f"WHOLE CHROMOSOMES IDs: {whole_ID}", f"OTHER IDs: {other_ID}" ]
            return res
        else:
            return {"fragmented": fragmented, "whole": whole, "other": other, "fragmented IDs": fragmented_ID, "whole IDs": whole_ID, "other IDs": other_ID, "fraction": fraction}

    
    
class get_ens_hav(Operation):
    
    '''returns a subset of the dataframe containing entries from ensembl, havana or ensembl_havana'''
    
    def __init__(self):
        self.name= "get_ens_hav"
    
    
    def _execute (self, df):
        ''' takes a dataframe as argument, returns another dataframe object containing only the entries that have "ensembl", "havana" or "ensembl_havana" as Source'''
        
        
        ens_hav=df[df["Source"].isin(["ensembl", "havana", "ensembl_havana"])] 
        return ens_hav
    

class count_ens_hav(Operation):
    '''returns a list or a series with the number of entries for ens, hav or ens_hav sources'''
    
    def __init__(self):
        self.name= "count_ens_hav"
    
   
    def _execute(self, df, to_list= True):
        ''' takes a dataframe as argument,
            Prints a string containing the information
           Returns a series with the number of entries for each source'''
        
        
        enshav= df[df["Source"].isin(["ensembl", "havana", "ensembl_havana"])]
        groups= enshav.groupby("Source").count()
        n_ent=groups["SeqID"]
        res= ["Here you can find the number of entries from Ensembl, Havana and Ensembl_Havana"]
        
        if to_list: 
            for name, value in n_ent.items():
                res.append(f"{name}: {value}")
            return res 
                
        else: 
            return groups["SeqID"]
    
    

class get_gene_names(Operation):
    '''return a list or a series with  the gene names present in the dataset'''
    
    def __init__(self):
        self.name= "get_gene_names"
    
    
    def _execute (self, df, to_list=True):
        '''Takes a dataframe as argument,
            Extracts the name attribute for the entries with type gene present in the ens_hav dataset.
            returns a Series containing the Name and the index for each gene in the dataframe.'''
        
        #take only ens_hav, ens, hav entries
        enshav=df[df["Source"].isin(["ensembl", "havana", "ensembl_havana"])]
        
        #select only features of type gene
        genes= enshav[enshav["Type"]== "gene"]
        
        #generate attribute dictionary
        att_dict= GffDataset.attributes_dict(genes)
        
        #initialie two lists, one for the gene name and one for the gene index
        gene_names=[]
        gene_index=[]
        
        #append index and gene_name from the dictionary 
        for i in att_dict.keys():
            if "Name" in att_dict[i].keys():
                gene_names.append(att_dict[i]["Name"])
                gene_index.append(i)
                
                
        res= ["Here you can find all the entries in the dataset that represent genes, along with the relative index in the original dataset"]
        
        if to_list:
            for i in range(len(gene_names)):
                res.append(f" Gene Name: {gene_names[i]}, Index: {gene_index[i]}")
            return res
            
        else:         
            return pd.Series(gene_names, index= gene_index)
                
     
        
        
        
class experiment(Operation):
    
    def __init__(self):
        self.name= "experiment"
    
    def _execute(self, df):
        return "Hello"
           
    
       

    
    
            




            
            
            
    

        
    
    

        